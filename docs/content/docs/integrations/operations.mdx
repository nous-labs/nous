---
title: Operational Helpers
description: Transaction builders, request caching, and resilient retry loops for shared services.
---

import { Callout } from 'fumadocs-ui/components/callout';

# Operational helpers

These recipes keep your services fast and resilient when they perform thousands of contract queries per minute.

## Transaction builder utilities

`SmartContractQuery` (exported from `@nvlabs/qts/utils`) eliminates hex gymnastics:

```typescript
import { SmartContractQuery, QUBIC_CONTRACTS } from '@nvlabs/qts/utils';
import { QubicLiveClient } from '@nvlabs/qts';

const client = new QubicLiveClient();

const query = new SmartContractQuery(QUBIC_CONTRACTS.QUTIL, 2)
  .addIdentity('GARTHFANXMPXMDPEZFQPWFPYMHOAWTKILINCTRMVLFFVATKVJRKEDYXGHJBF')
  .addInt64(1234n); // asset name or offset

const response = await query.execute(client);
```

Prefer the helper factories for shorter code:

```typescript
import { createQuery, parseResponse } from '@nvlabs/qts/utils';

const q = createQuery(QUBIC_CONTRACTS.QSWAP, 4)
  .addIdentity(issuer)
  .addInt64(assetName)
  .addInt64(1_000_000n);

const parser = parseResponse((await q.execute(client)).responseData);
const amountOut = parser.readInt64();
```

`SmartContractResponse` keeps track of offsets so you can interleave reads and skips.

## Request caching layer

Contract responses are valid for a tick. Cache them with a composite key of `(contractIndex, inputType, inputHash)` plus
the tick number:

```typescript
import type { QuerySmartContractResponse } from '@nvlabs/qts';

interface CacheEntry {
  tick: number;
  payload: QuerySmartContractResponse;
}

class ContractCache {
  private store = new Map<string, CacheEntry>();

  private key(contractIndex: number, inputType: number, requestData: string) {
    return `${contractIndex}:${inputType}:${requestData}`;
  }

  get(contractIndex: number, inputType: number, requestData: string, tick: number) {
    const entry = this.store.get(this.key(contractIndex, inputType, requestData));
    return entry && entry.tick === tick ? entry.payload : null;
  }

  set(contractIndex: number, inputType: number, requestData: string, tick: number, payload: QuerySmartContractResponse) {
    this.store.set(this.key(contractIndex, inputType, requestData), { tick, payload });
  }
}
```

Usage:

```typescript
import { QUBIC_CONTRACTS, createQuery, parseResponse } from '@nvlabs/qts/utils';
import { QubicLiveClient } from '@nvlabs/qts';

const cache = new ContractCache();

async function getQxFees(client: QubicLiveClient) {
  const tick = (await client.getTickInfo()).tickInfo.tick;
  const cached = cache.get(QUBIC_CONTRACTS.QX, 1, '', tick);
  if (cached) return parseResponse(cached.responseData).readInt32();

  const response = await createQuery(QUBIC_CONTRACTS.QX, 1).execute(client);
  cache.set(QUBIC_CONTRACTS.QX, 1, '', tick, response);
  return parseResponse(response.responseData).readInt32();
}
```

Persist the cache (Redis, Memcached) when you need to share data across instances.

## Automatic retry logic with exponential backoff

Wrap remote calls with a retry helper that respects HTTP status codes:

```typescript
import { QubicLiveClient } from '@nvlabs/qts';
import type { QubicApiError } from '@nvlabs/qts';

async function withBackoff<T>(fn: () => Promise<T>, retries = 3, delayMs = 250): Promise<T> {
  try {
    return await fn();
  } catch (error) {
    const apiError = error as QubicApiError;
    if (retries === 0 || (apiError.status && apiError.status < 500 && apiError.status !== 408)) {
      throw error;
    }

    await new Promise((resolve) => setTimeout(resolve, delayMs));
    return withBackoff(fn, retries - 1, delayMs * 2);
  }
}

const client = new QubicLiveClient();
const tickInfo = await withBackoff(() => client.getTickInfo());
```

Pair this helper with `Promise.allSettled` when hitting multiple contracts in parallel.

## Request coalescing

If several parts of your service ask for the same data simultaneously, deduplicate the work with an in-flight map:

```typescript
import { qutil } from '@nvlabs/qts/utils';

const inflight = new Map<string, Promise<any>>();

async function fetchOnce<T>(key: string, fn: () => Promise<T>): Promise<T> {
  if (inflight.has(key)) return inflight.get(key) as Promise<T>;

  const task = fn()
    .finally(() => inflight.delete(key));

  inflight.set(key, task);
  return task;
}

const pollInfo = await fetchOnce(`qutil:poll:${pollId}`, () =>
  qutil.getPollInfo(client, pollId)
);
```

## Observability guardrails

- Log `inputSize` plus `(contractIndex, inputType)` per request. It surfaces slow or malformed calls immediately.
- Surface cache hit ratios per contract to know when to increase TTLs or add memoisation.
- Emit metrics for retry counts. If retries spike, consider spreading calls across multiple RPC endpoints.
- Store `WalletConnectAdapter` session topics in encrypted storage so API workers can resume signing after restarts.

## Related reading

- [Smart Contracts](/docs/smart-contracts) – deep dive on the builder and parser APIs.
- [Back-end APIs](/docs/integrations/backend) – apply these helpers to Express, Hono, or Elysia.
- [Examples](/docs/examples) - copy-paste ready-to-run scripts before baking them into jobs.
